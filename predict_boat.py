import pandas as pd
import numpy as np
import lightgbm as lgb
import time
import os

# ==========================================
# âš™ï¸ è¨­å®šã‚¨ãƒªã‚¢
# ==========================================
CSV_PATH = r"C:\Users\TAKUMA\ç«¶è‰‡ã«å‹ã¤\ç«¶è‰‡ãƒ‡ãƒ¼ã‚¿\FINAL_FULL_DATA_2025_FIXED.csv"

def log(msg):
    print(f"[{time.strftime('%H:%M:%S')}] {msg}", flush=True)

# ==========================================
# 1. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆã‚·ãƒŠã‚¸ãƒ¼ãƒ»ãƒ¢ãƒ‡ãƒ«ï¼‰
# ==========================================
def engineer_synergy_features(df):
    log("ğŸ› ï¸ ã‚·ãƒŠã‚¸ãƒ¼ç‰¹å¾´é‡ã‚’ç”Ÿæˆä¸­ï¼ˆå‹ç‡Ã—ã‚¹ã‚¿ãƒ¼ãƒˆã®ç›¸é–¢ãªã©ï¼‰...")
    
    # é¸æ‰‹ã®å®ŸåŠ›ã¨ã‚¹ã‚¿ãƒ¼ãƒˆã®æ›ã‘åˆã‚ã›ï¼ˆæœ€å¼·ã®æŒ‡æ¨™ï¼‰
    for i in range(1, 7):
        # å‹ç‡ãŒé«˜ãã€ã‹ã¤STãŒæ—©ã„ï¼ˆæ•°å€¤ãŒå°ã•ã„ï¼‰ã»ã©é«˜ã„å€¤ã«ãªã‚‹æŒ‡æ¨™
        df[f'power_idx_{i}'] = df[f'wr{i}'] * (1.0 / (df[f'st{i}'] + 0.01))
        
    # 1å·è‰‡ã¨ä»–è‰‡ã®åœ§å€’çš„æ ¼å·®
    df['top_power_gap'] = df['power_idx_1'] / (df[[f'power_idx_{i}' for i in range(2, 7)]].max(axis=1) + 0.001)
    
    # ä¼šå ´ã”ã¨ã®å¹³å‡çš„ãªã€Œè’ã‚Œåº¦ã€
    venue_hit_rate = df.groupby('jcd')['res1'].transform('mean')
    df['venue_stability'] = venue_hit_rate

    # å±•ç¤ºã®ç›¸å¯¾è©•ä¾¡ï¼ˆ1å·è‰‡ãŒã©ã‚Œã ã‘æŠœã‘ã¦ã„ã‚‹ã‹ï¼‰
    ex_mean = df[[f'ex{i}' for i in range(1, 7)]].mean(axis=1)
    df['ex_1_diff'] = ex_mean - df['ex1']

    df['jcd'] = df['jcd'].astype('category')
    return df

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
df = pd.read_csv(CSV_PATH).dropna(subset=['rank1', 'rank2', 'tansho', 'nirentan'])
df = engineer_synergy_features(df)

features = ['jcd', 'rno', 'wind', 'venue_stability', 'top_power_gap', 'ex_1_diff']
for i in range(1, 7):
    features.extend([f'wr{i}', f'st{i}', f'ex{i}', f'power_idx_{i}'])

# æ­£è§£ãƒ©ãƒ™ãƒ«
df['target_tan'] = df['rank1'].astype(int) - 1
combinations = [f"{f}-{s}" for f in range(1, 7) for s in range(1, 7) if f != s]
combo_to_id = {c: i for i, c in enumerate(combinations)}
df['target_niren'] = (df['rank1'].astype(int).astype(str) + "-" + df['rank2'].astype(int).astype(str)).map(combo_to_id)
df = df.dropna(subset=['target_niren'])

# åˆ†å‰²
split_idx = int(len(df) * 0.8)
train_df, test_df = df.iloc[:split_idx], df.iloc[split_idx:]

# ==========================================
# 2. è¶…ãƒ»æ·±å±¤å­¦ç¿’ï¼ˆé™ç•Œã¾ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½ã„è¾¼ã‚€ï¼‰
# ==========================================
def train_limit_model(y_col, num_class):
    log(f"ğŸ§  {y_col} ã®é™ç•Œå­¦ç¿’ï¼ˆæœ€å¼·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰ã‚’å®Ÿè¡Œä¸­...")
    lgb_train = lgb.Dataset(train_df[features], label=train_df[y_col])
    lgb_eval = lgb.Dataset(test_df[features], label=test_df[y_col], reference=lgb_train)
    
    params = {
        'objective': 'multiclass',
        'num_class': num_class,
        'metric': 'multi_logloss',
        'num_leaves': 511,         # æœ€å¤§é™ã®è¤‡é›‘ã•ã‚’è¨±å®¹
        'learning_rate': 0.002,    # æ¥µé™ã¾ã§æ…é‡ã«å­¦ç¿’
        'feature_fraction': 0.6,
        'bagging_fraction': 0.6,
        'bagging_freq': 1,
        'min_data_in_leaf': 10,
        'lambda_l1': 1.0,          # å³ã—ã„ãƒšãƒŠãƒ«ãƒ†ã‚£ã§ãƒã‚¤ã‚ºã‚’æ’é™¤
        'lambda_l2': 1.0,
        'verbose': -1,
        'seed': 42
    }
    
    return lgb.train(
        params, lgb_train, 
        num_boost_round=10000,     # éå¸¸ã«é•·ã„å­¦ç¿’
        valid_sets=[lgb_train, lgb_eval],
        callbacks=[lgb.early_stopping(stopping_rounds=300)]
    )

model_tan = train_limit_model('target_tan', 6)
model_niren = train_limit_model('target_niren', 30)

# ==========================================
# 3. ç©¶æ¥µã®é™ç•Œåˆ†æ
# ==========================================
def analyze_ultimate(model, name, is_niren=False):
    probs = model.predict(test_df[features])
    preds = np.argmax(probs, axis=1)
    confs = np.max(probs, axis=1)
    y_test = test_df['target_niren' if is_niren else 'target_tan'].values
    
    print(f"\nğŸ‘‘ ã€{name}ã€‘ ç©¶æ¥µé™ç•Œåˆ†æçµæœ")
    print("è‡ªä¿¡åº¦ | çš„ä¸­ç‡ | ãƒ¬ãƒ¼ã‚¹æ•° | å›åç‡")
    print("-----------------------------------------")
    
    # ã•ã‚‰ã«é«˜ã„è‡ªä¿¡åº¦ã‚’ãƒã‚§ãƒƒã‚¯
    thresholds = [0.85, 0.9, 0.92, 0.95] if not is_niren else [0.35, 0.4, 0.45, 0.5]
    
    for th in thresholds:
        mask = confs >= th
        if mask.sum() == 0: continue
        
        acc = (preds[mask] == y_test[mask]).mean() * 100
        payouts = test_df.iloc[mask]['nirentan' if is_niren else 'tansho']
        rec = (payouts[preds[mask] == y_test[mask]].sum() / (mask.sum() * 100)) * 100
        print(f"{th*100:2.0f}%  | {acc:6.2f}% | {mask.sum():5d}R | {rec:6.2f}%")

analyze_ultimate(model_tan, "å˜å‹")
analyze_ultimate(model_niren, "äºŒé€£å˜", True)