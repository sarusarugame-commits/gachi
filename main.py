import os, zipfile
if not os.path.exists('boat_model_nirentan.txt'):
    print('ğŸ§© åˆ†å‰²ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’çµåˆä¸­...')
    with open('recombined_model.zip', 'wb') as f_out:
        for i in range(1, 10):
            part = f'model_part_{i}'
            if os.path.exists(part):
                with open(part, 'rb') as f_in: f_out.write(f_in.read())
    with zipfile.ZipFile('recombined_model.zip', 'r') as f: f.extractall()

import zipfile, os
if os.path.exists('model.zip') and not os.path.exists('boat_model_nirentan.txt'):
    with zipfile.ZipFile('model.zip', 'r') as f: f.extractall()

import os
import json
import datetime
import time
import random
import re
import requests
import pandas as pd
import numpy as np
import lightgbm as lgb
import google.generativeai as genai
from bs4 import BeautifulSoup
from discordwebhook import Discord

# ==========================================
# âš™ï¸ åŸºæœ¬è¨­å®š
# ==========================================
BET_AMOUNT = 1000
genai.configure(api_key=os.environ["GEMINI_API_KEY"])
model_gemini = genai.GenerativeModel('gemini-3-flash-preview')
discord = Discord(url=os.environ["DISCORD_WEBHOOK_URL"])

# ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã®å®šç¾©
MODEL_FILE = 'boat_model_nirentan.txt'
COMBOS = [f"{f}-{s}" for f in range(1, 7) for s in range(1, 7) if f != s]

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
    "Referer": "https://www.boatrace.jp/",
}

# ==========================================
# ğŸ› ï¸ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ»ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ==========================================

def get_soup(url):
    time.sleep(random.uniform(1.5, 3.0))
    res = requests.get(url, headers=HEADERS, timeout=20)
    res.encoding = res.apparent_encoding
    return BeautifulSoup(res.text, 'html.parser')

def fetch_active_races(date):
    """ä»Šæ—¥é–‹å‚¬ã•ã‚Œã¦ã„ã‚‹ä¼šå ´ã¨ãƒ¬ãƒ¼ã‚¹ã‚’å–å¾—"""
    url = f"https://www.boatrace.jp/owpc/pc/race/index?hd={date}"
    soup = get_soup(url)
    found = []
    # é–‹å‚¬å ´ã®ãƒªãƒ³ã‚¯ã‹ã‚‰jcdã‚’å–å¾—
    for a in soup.select('a[href*="jcd="]'):
        m = re.search(r'jcd=(\d{2})', a.get('href'))
        if m: found.append(m.group(1))
    return sorted(list(set(found)))

def scrape_race_data(jcd, rno, date):
    """å‡ºèµ°è¡¨(wr, mo, f, st)ã¨ç›´å‰æƒ…å ±(ex, wind)ã‚’å–å¾—"""
    data = {'jcd': int(jcd), 'rno': int(rno)}
    
    # 1. å‡ºèµ°è¡¨ãƒšãƒ¼ã‚¸
    url_prog = f"https://www.boatrace.jp/owpc/pc/race/racelist?rno={rno}&jcd={jcd}&hd={date}"
    soup_prog = get_soup(url_prog)
    
    # é¸æ‰‹ã®å‹ç‡(wr), ãƒ¢ãƒ¼ã‚¿ãƒ¼(mo), Fæ•°(f), å¹³å‡ST(st)
    # boatrace.jpã®å‡ºèµ°è¡¨ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã‚’è§£æ
    for i in range(1, 7):
        tbody = soup_prog.select(f'tbody.is-fs12')[i-1]
        # å…¨å›½å‹ç‡
        data[f'wr{i}'] = float(tbody.select('td')[3].select_one('div').contents[0].strip())
        # ãƒ¢ãƒ¼ã‚¿ãƒ¼2é€£ç‡
        data[f'mo{i}'] = float(tbody.select('td')[6].select_one('div').contents[0].strip())
        # Fæ•°
        f_text = tbody.select('td')[2].text.strip()
        data[f'f{i}'] = int(re.search(r'F(\d)', f_text).group(1)) if 'F' in f_text else 0
        # å¹³å‡ST
        st_text = tbody.select('td')[2].select_one('div').contents[-1].strip()
        data[f'st{i}'] = float(st_text) if st_text != '-' else 0.20

    # 2. ç›´å‰æƒ…å ±ãƒšãƒ¼ã‚¸ (å±•ç¤ºã‚¿ã‚¤ãƒ , é¢¨é€Ÿ)
    url_before = f"https://www.boatrace.jp/owpc/pc/race/beforeinfo?rno={rno}&jcd={jcd}&hd={date}"
    soup_before = get_soup(url_before)
    
    # é¢¨é€Ÿ
    wind_elem = soup_before.select_one('.is-wind')
    data['wind'] = float(re.search(r'(\d+)m', wind_elem.text).group(1)) if wind_elem else 0.0
    
    # å±•ç¤ºã‚¿ã‚¤ãƒ  (ex)
    ex_table = soup_before.select_one('div.is-overflow table')
    if ex_table:
        rows = ex_table.select('tbody tr')
        for i in range(1, 7):
            ex_val = rows[i-1].select('td')[4].text.strip()
            data[f'ex{i}'] = float(ex_val) if ex_val != '-' else 6.80
    else:
        return None # å±•ç¤ºãŒã¾ã ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    
    return data

def engineer_features(df):
    """æ·»ä»˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°"""
    for i in range(1, 7):
        df[f'power_idx_{i}'] = df[f'wr{i}'] * (1.0 / (df[f'st{i}'] + 0.01))
    for i in range(1, 6):
        df[f'st_gap_{i}_{i+1}'] = df[f'st{i+1}'] - df[f'st{i}']
        df[f'wr_gap_{i}_{i+1}'] = df[f'wr{i}'] - df[f'wr{i+1}']
    avg_wr = df[[f'wr{i}' for i in range(1, 7)]].mean(axis=1)
    df['wr_1_vs_avg'] = df['wr1'] / (avg_wr + 0.001)
    df['jcd'] = df['jcd'].astype('category')
    return df

# ==========================================
# ğŸš€ ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# ==========================================

def main():
    if not os.path.exists('status.json'):
        with open('status.json', 'w') as f: json.dump({"notified": [], "results": [], "total_balance": 0}, f)
    
    with open('status.json', 'r') as f: status = json.load(f)
    today = datetime.datetime.now().strftime('%Y%m%d')
    bst = lgb.Booster(model_file=MODEL_FILE)
    
    jcds = fetch_active_races(today)
    
    for jcd in jcds:
        for rno in range(1, 13):
            race_id = f"{today}_{jcd}_{rno}"
            
            # --- å‹è² åˆ¤æ–­ ---
            if not any(n['id'] == race_id for n in status["notified"]):
                try:
                    raw_data = scrape_race_data(jcd, rno, today)
                    if not raw_data: continue # å±•ç¤ºå‰
                    
                    df = pd.DataFrame([raw_data])
                    df = engineer_features(df)
                    
                    # ç‰¹å¾´é‡ã®ä¸¦ã³é †ã‚’å­¦ç¿’æ™‚ã«åˆã‚ã›ã‚‹(finalize_model.pyå‚ç…§)
                    features = ['jcd', 'rno', 'wind', 'wr_1_vs_avg']
                    for i in range(1, 7): features.extend([f'wr{i}', f'st{i}', f'ex{i}', f'power_idx_{i}'])
                    for i in range(1, 6): features.extend([f'st_gap_{i}_{i+1}', f'wr_gap_{i}_{i+1}'])
                    
                    probs = bst.predict(df[features])[0]
                    best_idx = np.argmax(probs)
                    prob = probs[best_idx]
                    combo = COMBOS[best_idx]
                    
                    # ã‚ªãƒƒã‚ºå–å¾—
                    res_odds = requests.get(f"https://www.boatrace.jp/owpc/pc/race/odds2t?rno={rno}&jcd={jcd}&hd={today}", headers=HEADERS)
                    soup_odds = BeautifulSoup(res_odds.text, 'html.parser')
                    # ã‚ªãƒƒã‚ºæŠ½å‡º(ç°¡æ˜“)
                    odds = 1.0
                    for table in soup_odds.select('table.is-p_auto'):
                        for tr in table.select('tbody tr'):
                            if tr.select('td')[0].text.strip() == combo.split('-')[1] and tr.parent.parent.parent.select_one('thead').text.strip() == combo.split('-')[0]:
                                odds = float(tr.select('td')[1].text.strip())

                    ev = prob * odds
                    
                    if ev > 1.2 and prob > 0.4: # æ¡ä»¶
                        prompt = f"çš„ä¸­ç‡{prob*100:.1f}%ã€æœŸå¾…å€¤{ev:.2f}ã®ã€Œ{combo}ã€ã¯è²·ã„ã§ã™ã‹ï¼Ÿ"
                        res_gemini = model_gemini.generate_content(prompt).text
                        
                        if "è²·ã„" in res_gemini or "å¼·æ°—" in res_gemini:
                            live_url = f"https://www.boatrace.jp/owpc/pc/race/videolive?jcd={jcd}&hd={today}"
                            discord.post(content=f"ğŸš€ **å‹è² ï¼ {jcd}#{rno}R**\nè²·ã„ç›®: {combo}\n{res_gemini}\nğŸ“º {live_url}")
                            status["notified"].append({"id": race_id, "jcd": jcd, "rno": rno, "combo": combo, "amount": BET_AMOUNT})
                except Exception as e:
                    print(f"Error prediction {race_id}: {e}")

            # --- çµæœç¢ºèª ---
            for task in status["notified"]:
                if any(r['id'] == task['id'] for r in status["results"]): continue
                
                try:
                    url_res = f"https://www.boatrace.jp/owpc/pc/race/raceresult?rno={task['rno']}&jcd={task['jcd']}&hd={today}"
                    soup_res = get_soup(url_res)
                    table = soup_res.select_one('table.is-w600') # é…å½“è¡¨
                    if table:
                        found_res = None; payout = 0
                        for tr in table.select('tr'):
                            if '2é€£å˜' in tr.text:
                                found_res = tr.select('td')[0].text.strip().replace(' ', '')
                                payout = int(tr.select('td')[1].text.strip().replace('Â¥', '').replace(',', ''))
                        
                        if found_res:
                            hit = (found_res == task['combo'])
                            profit = (payout * (task['amount'] // 100)) - task['amount'] if hit else -task['amount']
                            status["total_balance"] += profit
                            discord.post(content=f"ğŸ **çµæœ: {task['id']}**\n{found_res} ({'âœ…çš„ä¸­' if hit else 'âŒä¸çš„ä¸­'})\nåæ”¯: {profit:+}å†† / é€šç®—: {status['total_balance']:,}å††")
                            status["results"].append({"id": task["id"]})
                except Exception as e:
                    print(f"Error result {task['id']}: {e}")

    with open('status.json', 'w') as f: json.dump(status, f, indent=4)

if __name__ == "__main__":
    main()